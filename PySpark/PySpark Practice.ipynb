{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c6ab27-5ab8-43ae-8ff1-addb16dabf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.5.4)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from pyspark) (0.10.9.7)\n"
     ]
    }
   ],
   "source": [
    "# Install PySpark in the current Jupyter environment\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e860c803-2618-43bd-a097-5a69a246319a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point for DataFrame and SQL in PySpark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a2e83e-92c4-4b7f-ba8a-93898578152f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkSession\n",
    "# Syntax: SparkSession.builder.appName(\"AppName\").getOrCreate()\n",
    "spark = SparkSession.builder\\\n",
    "    .appName(\"MyApp\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a886346b-3bab-4f86-944b-5150f0b178b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+----+---+-----------+\n",
      "|              Order|              Status|     Category|Size|Qty|      State|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CSV file path\n",
    "# Syntax: csv_file_path = \"your_path_here\"\n",
    "csv_file_path = r\"C:\\Users\\Admin\\OneDrive\\Desktop\\Study\\Pandas\\order.csv\"\n",
    "\n",
    "# Read CSV as DataFrame\n",
    "# Syntax: spark.read.csv(path, header=True, inferSchema=True)\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)\n",
    "\n",
    "# Show 5 rows\n",
    "# Syntax: df.show(n)\n",
    "df.show(5)\n",
    "\n",
    "# Stop SparkSession (optional)\n",
    "# Syntax: spark.stop()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "260612ac-d8cb-403f-835e-97becca124af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Order', 'string'),\n",
       " ('Status', 'string'),\n",
       " ('Category', 'string'),\n",
       " ('Size', 'string'),\n",
       " ('Qty', 'int'),\n",
       " ('State', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Returns a list of (column_name, data_type) for the DataFrame\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec09f54-fc66-4dea-8352-50d6e3d59d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- Size: string (nullable = true)\n",
      " |-- Qty: integer (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame schema in tree format\n",
    "# Syntax: df.printSchema()\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6081ceb9-770b-4dd0-bde1-dae1feb638ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+----+---+-----------+\n",
      "|              Order|              Status|     Category|Size|Qty|   Location|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename column and show 5 rows\n",
    "# Syntax: df.withColumnRenamed(\"old_name\", \"new_name\")\n",
    "df.withColumnRenamed('State', 'Location').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b03e8e28-671b-473b-9dce-09fd380fc645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|      State|\n",
      "+-----------+\n",
      "|MAHARASHTRA|\n",
      "|  KARNATAKA|\n",
      "|MAHARASHTRA|\n",
      "| PUDUCHERRY|\n",
      "| TAMIL NADU|\n",
      "+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select a single column and show 5 rows\n",
    "# Syntax: df.select(\"column_name\").show(n)\n",
    "df.select('State').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d850448e-489d-47d1-9de6-8792a5129dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+\n",
      "|              Order|      State|\n",
      "+-------------------+-----------+\n",
      "|405-8078784-5731545|MAHARASHTRA|\n",
      "|171-9198151-1101146|  KARNATAKA|\n",
      "|404-0687676-7273146|MAHARASHTRA|\n",
      "|403-9615377-8133951| PUDUCHERRY|\n",
      "|407-1069790-7240320| TAMIL NADU|\n",
      "+-------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select multiple columns and show 5 rows\n",
    "# Syntax: df.select(\"col1\", \"col2\", ...).show(n)\n",
    "df.select('Order', 'State').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b850e3d-1def-4152-9333-22a72122f648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+---+---+-----------+\n",
      "|                  a|                   b|            c|  d|  e|          f|\n",
      "+-------------------+--------------------+-------------+---+---+-----------+\n",
      "|405-8078784-5731545|           Cancelled|          Set|  S|  0|MAHARASHTRA|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta|3XL|  1|  KARNATAKA|\n",
      "|404-0687676-7273146|             Shipped|        kurta| XL|  1|MAHARASHTRA|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|  L|  0| PUDUCHERRY|\n",
      "|407-1069790-7240320|             Shipped|          Top|3XL|  1| TAMIL NADU|\n",
      "+-------------------+--------------------+-------------+---+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename all columns using a list\n",
    "# Syntax: df.toDF(*new_column_names_list).show(n)\n",
    "col = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "df.toDF(*col).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81dfafc3-54bb-459f-8f36-514fb1eef7c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+----+---+-----------+\n",
      "|              Order|              Status|Size|Qty|      State|\n",
      "+-------------------+--------------------+----+---+-----------+\n",
      "|405-8078784-5731545|           Cancelled|   S|  0|MAHARASHTRA|\n",
      "|171-9198151-1101146|Shipped - Deliver...| 3XL|  1|  KARNATAKA|\n",
      "|404-0687676-7273146|             Shipped|  XL|  1|MAHARASHTRA|\n",
      "|403-9615377-8133951|           Cancelled|   L|  0| PUDUCHERRY|\n",
      "|407-1069790-7240320|             Shipped| 3XL|  1| TAMIL NADU|\n",
      "+-------------------+--------------------+----+---+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop a column and show 5 rows\n",
    "# Syntax: df.drop(\"column_name\").show(n)\n",
    "df.drop('Category').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1987382a-ee6f-4b3c-82ed-618ebfebf90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+----+---+\n",
      "|              Order|     Category|Size|Qty|\n",
      "+-------------------+-------------+----+---+\n",
      "|405-8078784-5731545|          Set|   S|  0|\n",
      "|171-9198151-1101146|        kurta| 3XL|  1|\n",
      "|404-0687676-7273146|        kurta|  XL|  1|\n",
      "|403-9615377-8133951|Western Dress|   L|  0|\n",
      "|407-1069790-7240320|          Top| 3XL|  1|\n",
      "+-------------------+-------------+----+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop multiple columns and show 5 rows\n",
    "# Syntax: df.drop(\"col1\", \"col2\", ...).show(n)\n",
    "df.drop('Status', 'State').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "344a894e-9a69-4a58-9623-3ca9c595e27b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|              Status|      State|\n",
      "+--------------------+-----------+\n",
      "|           Cancelled|MAHARASHTRA|\n",
      "|Shipped - Deliver...|  KARNATAKA|\n",
      "|             Shipped|MAHARASHTRA|\n",
      "|           Cancelled| PUDUCHERRY|\n",
      "|             Shipped| TAMIL NADU|\n",
      "+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop columns using a list and show 5 rows\n",
    "# Syntax: df.drop(*list_of_columns).show(n)\n",
    "col = ['Order', 'Category', 'Size', 'Qty']\n",
    "df.drop(*col).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0e95cd4-9784-456e-9c02-b7d6f33944b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------+----+---+----------+\n",
      "|              Order|              Status|Category|Size|Qty|     State|\n",
      "+-------------------+--------------------+--------+----+---+----------+\n",
      "|406-7807733-3785945|Shipped - Deliver...|   kurta|   S|  1| TELANGANA|\n",
      "|171-9198151-1101146|Shipped - Deliver...|   kurta| 3XL|  1| KARNATAKA|\n",
      "|406-9379318-6555504|             Shipped|   kurta| XXL|  1| RAJASTHAN|\n",
      "|407-5443024-5233168|           Cancelled|     Set| 3XL|  0| TELANGANA|\n",
      "|407-1069790-7240320|             Shipped|     Top| 3XL|  1|TAMIL NADU|\n",
      "+-------------------+--------------------+--------+----+---+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get distinct rows and show n rows  \n",
    "# Syntax: df.distinct().show(n)\n",
    "df.distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "993f29aa-640d-43d3-b6f1-a30254968a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q: What does col() do in PySpark?\n",
    "# A: col() is used to access a DataFrame column by name. It allows column-level operations.\n",
    "\n",
    "# Q: What does lit() do in PySpark?\n",
    "# A: lit() is used to add constant values (like numbers or strings) to a column or expression.\n",
    "\n",
    "# Q: What does current_date() return in PySpark?\n",
    "# A: current_date() returns the current system date (no time component) in the default format.\n",
    "\n",
    "# Q: What is when() used for in PySpark?\n",
    "# A: when() is used for conditional logic, similar to if-else or CASE WHEN. It must be paired with otherwise().\n",
    "\n",
    "# Q: How do you create a column called \"Status\" which says \"OK\" if Qty > 50, else \"LOW\"?\n",
    "# A: df = df.withColumn(\"Status\", when(col(\"Qty\") > 50, \"OK\").otherwise(\"LOW\"))\n",
    "\n",
    "# Q: How do you add a column \"Updated\" which just contains todayâ€™s date?\n",
    "# A: df = df.withColumn(\"Updated\", current_date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba5ca698-93ff-4006-b7c2-dcd749c26d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import commonly used PySpark functions\n",
    "# Syntax: from pyspark.sql.functions import col, lit, current_date, when\n",
    "from pyspark.sql.functions import col, lit, current_date, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1575af11-3371-4929-9839-4ead4b54ae18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+----+---+-----------+---+\n",
      "|              Order|              Status|     Category|Size|Qty|      State|Net|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+---+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|  0|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|  2|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|  2|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|  0|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|  2|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new column by multiplying existing column\n",
    "# Syntax: df.withColumn(\"new_col\", col(\"existing_col\") * value).show(n)\n",
    "df.withColumn('Net', col('Qty') * 2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8639123b-77f5-47be-9d15-7b8b1bc37c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+----+---+-----------+---+\n",
      "|              Order|              Status|     Category|Size|Qty|      State|Net|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+---+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|  0|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|  2|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|  2|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|  0|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|  2|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with expression and show n rows  \n",
    "# Syntax: df.withColumn('NewCol', expression).show(n)\n",
    "df.withColumn('Net', col('Qty') * 2).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5758e686-97ab-4fbd-b7c2-479e2e2b3105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+----+---+-----------+----------+\n",
      "|              Order|              Status|     Category|Size|Qty|      State|      Date|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+----------+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|2025-08-06|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|2025-08-06|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|2025-08-06|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|2025-08-06|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|2025-08-06|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with current date  \n",
    "# Syntax: df.withColumn('col_name', lit(current_date()))\n",
    "df.withColumn('Date', lit(current_date())).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dcae0e02-3a13-4195-b422-9e89e00afb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+----+---+-----------+------+\n",
      "|              Order|              Status|     Category|Size|Qty|      State|Remark|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+------+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|     C|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|     B|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|     S|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|     C|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|     S|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------------------+--------------------+-------------+----+---+-----------+--------+\n",
      "|              Order|              Status|     Category|Size|Qty|      State|  Remark|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+--------+\n",
      "|405-8078784-5731545|           Cancelled|          Set|   S|  0|MAHARASHTRA|Refunded|\n",
      "|171-9198151-1101146|Shipped - Deliver...|        kurta| 3XL|  1|  KARNATAKA|    Paid|\n",
      "|404-0687676-7273146|             Shipped|        kurta|  XL|  1|MAHARASHTRA|    Paid|\n",
      "|403-9615377-8133951|           Cancelled|Western Dress|   L|  0| PUDUCHERRY|Refunded|\n",
      "|407-1069790-7240320|             Shipped|          Top| 3XL|  1| TAMIL NADU|    Paid|\n",
      "+-------------------+--------------------+-------------+----+---+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add new column 'Remark' based on conditions in 'Status'  \n",
    "# \"B\" if delivered, \"S\" if shipped, else \"C\"\n",
    "df.withColumn(\"Remark\", \n",
    "    when(col(\"Status\") == \"Shipped - Delivered to Buyer\", \"B\")\n",
    "    .when(col(\"Status\") == \"Shipped\", \"S\")\n",
    "    .otherwise(\"C\")\n",
    ").show(5)\n",
    "\n",
    "df.withColumn(\"Remark\", when(col(\"Status\") == \"Cancelled\", \"Refunded\").otherwise(\"Paid\")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cfc4df71-ee42-46b0-aa31-17ee21767f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------+----+---+-----------+\n",
      "|              Order|              Status|Category|Size|Qty|      State|\n",
      "+-------------------+--------------------+--------+----+---+-----------+\n",
      "|405-8078784-5731545|           Cancelled|     Set|   S|  0|MAHARASHTRA|\n",
      "|404-0687676-7273146|             Shipped|   kurta|  XL|  1|MAHARASHTRA|\n",
      "|405-5513694-8146768|Shipped - Deliver...|   kurta|  XS|  1|MAHARASHTRA|\n",
      "|408-7955685-3083534|             Shipped|     Set|  XS|  1|MAHARASHTRA|\n",
      "|408-1298370-1920302|Shipped - Deliver...|     Set|   L|  1|MAHARASHTRA|\n",
      "+-------------------+--------------------+--------+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where State is 'MAHARASHTRA'  \n",
    "# Syntax: df.filter(df[\"col_name\"] == \"value\")  \n",
    "df.filter(df[\"State\"] == \"MAHARASHTRA\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ceaab00-452e-43a1-83c8-e53256550e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+---------+--------+----+---+-----------+\n",
      "|              Order|   Status|Category|Size|Qty|      State|\n",
      "+-------------------+---------+--------+----+---+-----------+\n",
      "|405-8078784-5731545|Cancelled|     Set|   S|  0|MAHARASHTRA|\n",
      "+-------------------+---------+--------+----+---+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filtering the DataFrame `df` for rows where:- 'State' is exactly \"MAHARASHTRA\" - AND 'Remark' is exactly \"Refunded\"\n",
    "df.filter((col(\"State\") == \"MAHARASHTRA\") & (col(\"Status\") == \"Cancelled\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "47a0a18b-1f97-400a-a255-6ecd1b86d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame with headers and inferred schema\n",
    "csv_file_path = r'C:\\Users\\Admin\\OneDrive\\Desktop\\Study\\Pyspark\\Data.csv'\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "88d6ef1b-67af-47a2-a736-851ecc1e87e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  8| Hank| 40|     Portland|\n",
      "+---+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with any null values  \n",
    "# Syntax: df.dropna()\n",
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8eab963b-788c-46bc-8e67-67592df17b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  1|Alice|  25|     New York|\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  4|David|NULL|             |\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "|  7|Grace|NULL|      Seattle|\n",
      "|  8| Hank|  40|     Portland|\n",
      "| 10| Jack|NULL|       Boston|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with nulls in specific columns  \n",
    "# Syntax: df.dropna(subset=['col1', 'col2'])\n",
    "df.dropna(subset=['City', 'Name']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9d21e92d-68b9-4d4e-a3d8-cd518d9d6f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "|  8| Hank|  40|     Portland|\n",
      "|  1|Alice|  25|     New York|\n",
      "| 10| Jack|NULL|       Boston|\n",
      "|  6|Frank|  35|         NULL|\n",
      "|  9|  Ivy|  29|         NULL|\n",
      "|  4|David|NULL|             |\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  3| NULL|  30|      Chicago|\n",
      "|  7|Grace|NULL|      Seattle|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate rows  \n",
    "# Syntax: df.dropDuplicates()\n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5618adac-deef-4133-9e8e-8f1da4161195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  2|  Bob| 30|  Los Angeles|\n",
      "|  3| NULL| 30|      Chicago|\n",
      "|  4|David| 30|             |\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  6|Frank| 35|         NULL|\n",
      "|  7|Grace| 30|      Seattle|\n",
      "|  8| Hank| 40|     Portland|\n",
      "|  9|  Ivy| 29|         NULL|\n",
      "| 10| Jack| 30|       Boston|\n",
      "+---+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace all null values with 30  \n",
    "# Syntax: df.fillna(30)\n",
    "df.fillna(30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "10c1a4b8-3d80-4ad0-a97d-0f528fcd9e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports function to calculate the average, max value, min value, mode and median of a column\n",
    "from pyspark.sql.functions import mean, max, min, mode, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1c521b90-2c64-436b-8555-cf05754efab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          avg(Age)|\n",
      "+------------------+\n",
      "|31.166666666666668|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate and show the average (mean) of the 'Age' column  \n",
    "# Syntax: df.select(mean(df.ColumnName)).show()  \n",
    "df.select(mean(df.Age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b9230452-d509-49a6-ae92-14b4335d27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|max(Age)|\n",
      "+--------+\n",
      "|      40|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find and show the maximum value from the 'Age' column  \n",
    "# Syntax: df.select(max(df[\"ColumnName\"])).show()  \n",
    "df.select(max(df[\"Age\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2ebfb95-1972-43e2-9812-1d2e1b7be776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|min(Age)|\n",
      "+--------+\n",
      "|      25|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find and show the minimum value from the 'Age' column  \n",
    "# Syntax: df.select(min(df[\"ColumnName\"])).show()  \n",
    "df.select(min(df[\"Age\"])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ca574497-6139-470c-b3f4-b57df9e1821c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  2|  Bob| 31|  Los Angeles|\n",
      "|  3| NULL| 30|      Chicago|\n",
      "|  4|David| 31|             |\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  6|Frank| 35|         NULL|\n",
      "|  7|Grace| 31|      Seattle|\n",
      "|  8| Hank| 40|     Portland|\n",
      "|  9|  Ivy| 29|         NULL|\n",
      "| 10| Jack| 31|       Boston|\n",
      "+---+-----+---+-------------+\n",
      "\n",
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  2|  Bob| 31|  Los Angeles|\n",
      "|  3| NULL| 30|      Chicago|\n",
      "|  4|David| 31|             |\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  6|Frank| 35|         NULL|\n",
      "|  7|Grace| 31|      Seattle|\n",
      "|  8| Hank| 40|     Portland|\n",
      "|  9|  Ivy| 29|         NULL|\n",
      "| 10| Jack| 31|       Boston|\n",
      "+---+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Select mean value of Age column\n",
    "t = df.select(mean(df.Age))\n",
    "\n",
    "# Step 2: Extract that mean value from the DataFrame\n",
    "mean_value = t.collect()[0][0]\n",
    "\n",
    "# Step 3: Replace all null values with mean and show the updated DataFrame\n",
    "df.fillna(mean_value).show()\n",
    "\n",
    "# Optional: Replace nulls in Age column only\n",
    "df.fillna({\"Age\": mean_value}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "804b59f0-01ab-4df2-85a2-66818ab7ef86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|mode(Age)|\n",
      "+---------+\n",
      "|       25|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find and show the mode (most frequent value) from the 'Age' column\n",
    "# Syntax: df.select(mode(df[\"ColumnName\"]))\n",
    "df.select(mode(df.Age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a1fbdbb3-0c35-468f-838c-2bde59fe4a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|median(Age)|\n",
      "+-----------+\n",
      "|       29.5|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Find and show the median value from the 'Age' column  \n",
    "# Syntax: df.select(median(df[\"ColumnName\"])).show()\n",
    "df.select(median(df.Age)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b1ffd0a4-1c07-4048-9992-56f62e56ace7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-----------+\n",
      "| ID| Name| Age|       City|\n",
      "+---+-----+----+-----------+\n",
      "|  1|Alice|  25|   New York|\n",
      "|  2|  Bob|NULL|Los Angeles|\n",
      "|  3| NULL|  30|    Chicago|\n",
      "+---+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Limit the number of rows displayed to 3  \n",
    "# Syntax: df.limit(n).show()  \n",
    "df.limit(3).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52df0be0-1676-4eb8-a247-2c4f8670668a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|Years|\n",
      "+-----+\n",
      "|   25|\n",
      "| NULL|\n",
      "|   30|\n",
      "| NULL|\n",
      "|   28|\n",
      "|   35|\n",
      "| NULL|\n",
      "|   40|\n",
      "|   29|\n",
      "| NULL|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename a column temporarily using alias  \n",
    "# Syntax: df.select(df[\"col\"].alias(\"new_name\"))  \n",
    "df.select(df[\"Age\"].alias(\"Years\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8383e144-ef08-408a-b683-66550271653d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Name='Alice', Age=25, City='New York'),\n",
       " Row(ID=2, Name='Bob', Age=None, City='Los Angeles'),\n",
       " Row(ID=3, Name=None, Age=30, City='Chicago'),\n",
       " Row(ID=4, Name='David', Age=None, City=' '),\n",
       " Row(ID=5, Name='Eva', Age=28, City='San Francisco'),\n",
       " Row(ID=6, Name='Frank', Age=35, City=None),\n",
       " Row(ID=7, Name='Grace', Age=None, City='Seattle'),\n",
       " Row(ID=8, Name='Hank', Age=40, City='Portland'),\n",
       " Row(ID=9, Name='Ivy', Age=29, City=None),\n",
       " Row(ID=10, Name='Jack', Age=None, City='Boston')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return all rows as a list of Row objects  \n",
    "# Syntax: df.collect()  \n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f15a184d-3d74-47cb-9531-a5b20b7f49ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Name='Alice', Age=25, City='New York'),\n",
       " Row(ID=2, Name='Bob', Age=None, City='Los Angeles')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return first 2 rows as a list  \n",
    "# Syntax: df.take(n)  \n",
    "df.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c2808292-45b1-40c4-831b-4e355706fcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  1|Alice|  25|     New York|\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  3| NULL|  30|      Chicago|\n",
      "|  4|David|NULL|             |\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return only the first 5 rows from the DataFrame  \n",
    "# Syntax: df.limit(n).show()  \n",
    "df.limit(5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "8b63f5dc-8ff1-4178-8158-ff013bb51060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|PersonAge|\n",
      "+---------+\n",
      "|       25|\n",
      "|     NULL|\n",
      "|       30|\n",
      "|     NULL|\n",
      "|       28|\n",
      "|       35|\n",
      "|     NULL|\n",
      "|       40|\n",
      "|       29|\n",
      "|     NULL|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename a column temporarily using alias  \n",
    "# Syntax: df.select(df[\"col\"].alias(\"alias_name\"))  \n",
    "df.select(df[\"Age\"].alias(\"PersonAge\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "953c407f-4812-4e61-80f2-55b6e057c80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Name='Alice', Age=25, City='New York'),\n",
       " Row(ID=2, Name='Bob', Age=None, City='Los Angeles'),\n",
       " Row(ID=3, Name=None, Age=30, City='Chicago'),\n",
       " Row(ID=4, Name='David', Age=None, City=' '),\n",
       " Row(ID=5, Name='Eva', Age=28, City='San Francisco'),\n",
       " Row(ID=6, Name='Frank', Age=35, City=None),\n",
       " Row(ID=7, Name='Grace', Age=None, City='Seattle'),\n",
       " Row(ID=8, Name='Hank', Age=40, City='Portland'),\n",
       " Row(ID=9, Name='Ivy', Age=29, City=None),\n",
       " Row(ID=10, Name='Jack', Age=None, City='Boston')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect all rows into a list on driver (beware of large data!)  \n",
    "# Syntax: df.collect()  \n",
    "df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93a194cc-d407-418e-8618-391a456228b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Name='Alice', Age=25, City='New York'),\n",
       " Row(ID=2, Name='Bob', Age=None, City='Los Angeles'),\n",
       " Row(ID=3, Name=None, Age=30, City='Chicago')]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take first n rows and return as list  \n",
    "# Syntax: df.take(n)  \n",
    "df.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ce7ddedc-01b9-4c8c-881c-46fdd634e0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  1|Alice|  25|     New York|\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  3| NULL|  30|      Chicago|\n",
      "|  4|David|NULL|             |\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "|  6|Frank|  35|         NULL|\n",
      "|  7|Grace|NULL|      Seattle|\n",
      "|  8| Hank|  40|     Portland|\n",
      "|  9|  Ivy|  29|         NULL|\n",
      "| 10| Jack|NULL|       Boston|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display top 20 rows of the DataFrame  \n",
    "# Syntax: df.show()  \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "10f75cd0-cfd9-445e-af7a-f84b17b1fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print DataFrame schema in tree format  \n",
    "# Syntax: df.printSchema()  \n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf18916f-3cc6-4755-a04f-934ff74022f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+\n",
      "| Name| Age|\n",
      "+-----+----+\n",
      "|Alice|  25|\n",
      "|  Bob|NULL|\n",
      "| NULL|  30|\n",
      "|David|NULL|\n",
      "|  Eva|  28|\n",
      "|Frank|  35|\n",
      "|Grace|NULL|\n",
      "| Hank|  40|\n",
      "|  Ivy|  29|\n",
      "| Jack|NULL|\n",
      "+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns from the DataFrame  \n",
    "# Syntax: df.select(\"col1\", \"col2\")  \n",
    "df.select(\"Name\", \"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "896df335-a117-431f-bca3-ff4ca3135759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  8| Hank| 40|     Portland|\n",
      "+---+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with null values  \n",
    "# Syntax: df.dropna()  \n",
    "df.dropna().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2b3d3910-015e-4b1e-bf1b-f3e544169680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  2|  Bob| 30|  Los Angeles|\n",
      "|  3| NULL| 30|      Chicago|\n",
      "|  4|David| 30|             |\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  6|Frank| 35|         NULL|\n",
      "|  7|Grace| 30|      Seattle|\n",
      "|  8| Hank| 40|     Portland|\n",
      "|  9|  Ivy| 29|         NULL|\n",
      "| 10| Jack| 30|       Boston|\n",
      "+---+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Replace all null values with 30  \n",
    "# Syntax: df.fillna(30)  \n",
    "df.fillna(30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6c80089b-20e0-4a60-a3a3-1793129a8bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "|  8| Hank|  40|     Portland|\n",
      "|  1|Alice|  25|     New York|\n",
      "| 10| Jack|NULL|       Boston|\n",
      "|  6|Frank|  35|         NULL|\n",
      "|  9|  Ivy|  29|         NULL|\n",
      "|  4|David|NULL|             |\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  3| NULL|  30|      Chicago|\n",
      "|  7|Grace|NULL|      Seattle|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows from the DataFrame  \n",
    "# Syntax: df.dropDuplicates()  \n",
    "df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1c58ae5c-a488-4b53-995c-c47b971f80e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "|  8| Hank|  40|     Portland|\n",
      "|  1|Alice|  25|     New York|\n",
      "| 10| Jack|NULL|       Boston|\n",
      "|  6|Frank|  35|         NULL|\n",
      "|  9|  Ivy|  29|         NULL|\n",
      "|  4|David|NULL|             |\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  3| NULL|  30|      Chicago|\n",
      "|  7|Grace|NULL|      Seattle|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Return unique rows only (like SQL DISTINCT)  \n",
    "# Syntax: df.distinct()  \n",
    "df.distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9d705a12-49f2-429c-a398-df4f52781b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+--------+\n",
      "| ID| Name| Age|         City|AgePlus5|\n",
      "+---+-----+----+-------------+--------+\n",
      "|  1|Alice|  25|     New York|      30|\n",
      "|  2|  Bob|NULL|  Los Angeles|    NULL|\n",
      "|  3| NULL|  30|      Chicago|      35|\n",
      "|  4|David|NULL|             |    NULL|\n",
      "|  5|  Eva|  28|San Francisco|      33|\n",
      "|  6|Frank|  35|         NULL|      40|\n",
      "|  7|Grace|NULL|      Seattle|    NULL|\n",
      "|  8| Hank|  40|     Portland|      45|\n",
      "|  9|  Ivy|  29|         NULL|      34|\n",
      "| 10| Jack|NULL|       Boston|    NULL|\n",
      "+---+-----+----+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Add or update a column in the DataFrame  \n",
    "# Syntax: df.withColumn(\"NewCol\", expr)  \n",
    "df.withColumn(\"AgePlus5\", df[\"Age\"] + 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cfae8834-a181-4cc6-84c5-8b472d768d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+-----+-------------+\n",
      "| ID| Name|Years|         City|\n",
      "+---+-----+-----+-------------+\n",
      "|  1|Alice|   25|     New York|\n",
      "|  2|  Bob| NULL|  Los Angeles|\n",
      "|  3| NULL|   30|      Chicago|\n",
      "|  4|David| NULL|             |\n",
      "|  5|  Eva|   28|San Francisco|\n",
      "|  6|Frank|   35|         NULL|\n",
      "|  7|Grace| NULL|      Seattle|\n",
      "|  8| Hank|   40|     Portland|\n",
      "|  9|  Ivy|   29|         NULL|\n",
      "| 10| Jack| NULL|       Boston|\n",
      "+---+-----+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename an existing column  \n",
    "# Syntax: df.withColumnRenamed(\"old\", \"new\")  \n",
    "df.withColumnRenamed(\"Age\", \"Years\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dcf07526-aa9d-4b60-8cd4-96671265d6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+--------+\n",
      "| ID| Name|Age|    City|\n",
      "+---+-----+---+--------+\n",
      "|  6|Frank| 35|    NULL|\n",
      "|  8| Hank| 40|Portland|\n",
      "+---+-----+---+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows based on condition  \n",
    "# Syntax: df.filter(condition) or df.where(condition)  \n",
    "df.filter(df[\"Age\"] > 30).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a760f478-488e-455f-b8f3-954df7f9d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|         City|sum(Age)|\n",
      "+-------------+--------+\n",
      "|  Los Angeles|    NULL|\n",
      "|San Francisco|      28|\n",
      "|         NULL|      64|\n",
      "|     Portland|      40|\n",
      "|      Chicago|      30|\n",
      "|      Seattle|    NULL|\n",
      "|             |    NULL|\n",
      "|     New York|      25|\n",
      "|       Boston|    NULL|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group data and apply aggregation functions  \n",
    "# Syntax: df.groupBy(\"col\").agg(F.agg_func(\"col\"))  \n",
    "from pyspark.sql.functions import sum  \n",
    "df.groupBy(\"City\").agg(sum(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a98dcfc9-5c20-4459-ada0-dab10fc77070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+\n",
      "| ID| Name| Age|         City|\n",
      "+---+-----+----+-------------+\n",
      "|  2|  Bob|NULL|  Los Angeles|\n",
      "|  4|David|NULL|             |\n",
      "|  7|Grace|NULL|      Seattle|\n",
      "| 10| Jack|NULL|       Boston|\n",
      "|  1|Alice|  25|     New York|\n",
      "|  5|  Eva|  28|San Francisco|\n",
      "|  9|  Ivy|  29|         NULL|\n",
      "|  3| NULL|  30|      Chicago|\n",
      "|  6|Frank|  35|         NULL|\n",
      "|  8| Hank|  40|     Portland|\n",
      "+---+-----+----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort the DataFrame by column(s)  \n",
    "# Syntax: df.orderBy(\"col\") or df.sort(\"col\")  \n",
    "df.orderBy(\"Age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b26436be-f2a5-4126-a77d-94c08f988871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----+------------------+-------+\n",
      "|summary|                ID| Name|               Age|   City|\n",
      "+-------+------------------+-----+------------------+-------+\n",
      "|  count|                10|    9|                 6|      8|\n",
      "|   mean|               5.5| NULL|31.166666666666668|   NULL|\n",
      "| stddev|3.0276503540974917| NULL| 5.419102016632153|   NULL|\n",
      "|    min|                 1|Alice|                25|       |\n",
      "|    max|                10| Jack|                40|Seattle|\n",
      "+-------+------------------+-----+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate summary statistics for numeric columns  \n",
    "# Syntax: df.describe().show()  \n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "747eaa7f-8b3c-4ad4-9187-19d631a0df03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count total number of rows in the DataFrame  \n",
    "# Syntax: df.count()  \n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d7d1a325-f9b3-4100-912f-2d682fc860b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-----------+\n",
      "| ID| Name| Age|       City|\n",
      "+---+-----+----+-----------+\n",
      "|  2|  Bob|NULL|Los Angeles|\n",
      "|  4|David|NULL|           |\n",
      "|  7|Grace|NULL|    Seattle|\n",
      "| 10| Jack|NULL|     Boston|\n",
      "+---+-----+----+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows with null in a specific column  \n",
    "# Syntax: df.filter(df[\"col\"].isNull())  \n",
    "df.filter(df[\"Age\"].isNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "43008f7a-ddd1-4fa9-a9d4-b701e7cb209d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+---+-------------+\n",
      "| ID| Name|Age|         City|\n",
      "+---+-----+---+-------------+\n",
      "|  1|Alice| 25|     New York|\n",
      "|  3| NULL| 30|      Chicago|\n",
      "|  5|  Eva| 28|San Francisco|\n",
      "|  6|Frank| 35|         NULL|\n",
      "|  8| Hank| 40|     Portland|\n",
      "|  9|  Ivy| 29|         NULL|\n",
      "+---+-----+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where column is not null  \n",
    "# Syntax: df.filter(df[\"col\"].isNotNull())  \n",
    "df.filter(df[\"Age\"].isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "58851639-9711-4112-924c-17580b66d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert column to a different data type  \n",
    "# Syntax: df.withColumn(\"col\", df[\"col\"].cast(\"new_type\"))  \n",
    "df.withColumn(\"Age\", df[\"Age\"].cast(\"string\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4e6455b8-9d84-489e-bb7d-9cf7387c33d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+-------------+------+\n",
      "| ID| Name| Age|         City|Senior|\n",
      "+---+-----+----+-------------+------+\n",
      "|  1|Alice|  25|     New York|    No|\n",
      "|  2|  Bob|NULL|  Los Angeles|    No|\n",
      "|  3| NULL|  30|      Chicago|    No|\n",
      "|  4|David|NULL|             |    No|\n",
      "|  5|  Eva|  28|San Francisco|    No|\n",
      "|  6|Frank|  35|         NULL|    No|\n",
      "|  7|Grace|NULL|      Seattle|    No|\n",
      "|  8| Hank|  40|     Portland|    No|\n",
      "|  9|  Ivy|  29|         NULL|    No|\n",
      "| 10| Jack|NULL|       Boston|    No|\n",
      "+---+-----+----+-------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Apply conditional logic to create new column  \n",
    "# Syntax: df.withColumn(\"col\", when(condition, value))  \n",
    "from pyspark.sql.functions import when  \n",
    "df.withColumn(\"Senior\", when(df[\"Age\"] > 60, \"Yes\").otherwise(\"No\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "60dbf7f8-6d07-4e98-8142-5331bb4a16f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+\n",
      "|          avg(Age)|count(Name)|\n",
      "+------------------+-----------+\n",
      "|31.166666666666668|          9|\n",
      "+------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import common functions from pyspark.sql.functions  \n",
    "# Syntax: from pyspark.sql.functions import col, lit, avg, sum, count  \n",
    "from pyspark.sql.functions import col, lit, avg, sum, count  \n",
    "df.select(avg(\"Age\"), count(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a244553c-cd1a-47c6-864d-0f4033dd6f57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "| ID| Name| Age|\n",
      "+---+-----+----+\n",
      "|  1|Alice|  25|\n",
      "|  2|  Bob|NULL|\n",
      "|  3| NULL|  30|\n",
      "|  4|David|NULL|\n",
      "|  5|  Eva|  28|\n",
      "|  6|Frank|  35|\n",
      "|  7|Grace|NULL|\n",
      "|  8| Hank|  40|\n",
      "|  9|  Ivy|  29|\n",
      "| 10| Jack|NULL|\n",
      "+---+-----+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop one or more columns from DataFrame  \n",
    "# Syntax: df.drop(\"col1\", \"col2\")  \n",
    "df.drop(\"Phone\", \"City\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ffdfac39-ad17-4f41-8f07-dcd0d1d7f3f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Age=None, count=4)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find mode (most frequent value) from a column  \n",
    "# Syntax: df.groupBy(\"col\").count().orderBy(\"count\", ascending=False).first()  \n",
    "df.groupBy(\"Age\").count().orderBy(\"count\", ascending=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "1ae06825-8649-493b-973b-3ad3abb177e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29.0]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find median using approxQuantile  \n",
    "# Syntax: df.approxQuantile(\"col\", [0.5], 0.01)  \n",
    "df.approxQuantile(\"Age\", [0.5], 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8cb984-ad84-402f-adb8-5733ea120d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49619ddd-eb0f-407f-aab5-ee93fa85ca19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469a737-6433-4cfd-b317-0e390cdc6d60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
